{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 輝度値変換 \n","# \n","# 画像処理特論\n","# \n","# 村松 正吾 \n","# \n","# 動作確認: Python 3.7, PyTorch 1.8"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Intensity transforms\n","# \n","# Advanced Topics in Image Processing\n","# \n","# Shogo MURAMATSU\n","# \n","# Verified: Python 3.7, PyTorch 1.8\n","from PIL import Image\n","import requests\n","import torch\n","import torchvision\n","from matplotlib import pyplot as plt\n","im2double = torchvision.transforms.ConvertImageDtype(torch.double)\n","im2uint8 = torchvision.transforms.ConvertImageDtype(torch.uint8)\n","rgb2gray = torchvision.transforms.Grayscale()\n","totensor = torchvision.transforms.ToTensor()\n","topilimg = torchvision.transforms.ToPILImage()\n","locs = torch.linspace(0,1,256).numpy()\n","imhist = lambda x: plt.stem(locs,torch.histc(x,bins=256,min=0.,max=1.),markerfmt='None',use_line_collection=True)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# (Preparation of sample image)\n","# \n","# 本サンプルで利用する画像データを収めたdata フォルダにパスをとおす。\n","# \n","# Create a path to the data folder that contains images used in this sample.\n","\n","# Reading original image\n","#I = im2double(rgb2gray(totensor(Image.open('./data/firenzeRgb.jpg'))))\n","url = 'https://github.com/msiplab/AtipWork/raw/master/data/firenzeRgb.jpg'\n","I = im2double(rgb2gray(totensor(Image.open(requests.get(url, stream=True).raw))))\n","\n","plt.figure(1)\n","plt.imshow(topilimg(I),cmap='gray')\n","plt.title('Original')\n","plt.show()\n","plt.figure(2)\n","imhist(I)\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# (Negative conversion)\n","# \n","# $$y=T(x) = 1.0-x$$\n","\n","# Definition of negative conversion\n","Tn = lambda x: 1.0-x\n","plt.figure(3)\n","plt.plot(locs,Tn(locs))\n","plt.axis('square')\n","plt.grid()\n","plt.show()\n","# Negative conversion of image I\n","J = Tn(I)\n","plt.figure(4)\n","plt.imshow(topilimg(J),cmap='gray')\n","plt.title('Negative')\n","plt.show()\n","plt.figure(5)\n","imhist(J)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# (Contrast stretching)\n","# \n","# $$y=T(x) = \\frac{1}{2}(\\mathrm{sign}(2x-1)|2x-1|^{10^{-\\alpha}}+1)$$\n","\n","# Definition of contrast stretching\n","alpha = 1\n","Tc = lambda x: 0.5*(torch.sign(2.0*x-1.0)*(torch.pow(torch.abs(2.0*x-1.0),10**(-alpha)))+1.0)\n","plt.figure(6)\n","plt.plot(locs,Tc(torch.tensor(locs)).detach().numpy())\n","plt.axis('square')\n","plt.grid()\n","plt.show()\n","# Contrast stretching of image I\n","K = Tc(I)\n","plt.figure(7)\n","plt.imshow(topilimg(K),cmap='gray')\n","plt.title('Contrast stretching')\n","plt.show()\n","plt.figure(8)\n","imhist(K)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# (Power law conversion)\n","# \n","# $$y=T(x) = x^\\gamma$$  \n","\n","# Definition of power law conversion\n","gamma = 0.5\n","Tp = lambda x: x**gamma\n","plt.figure(9)\n","plt.plot(locs,Tp(locs))\n","plt.axis('square')\n","plt.grid()\n","plt.show()\n","# Power law conversion of image I\n","L = Tp(I)\n","plt.figure(10)\n","plt.imshow(topilimg(L),cmap='gray')\n","plt.title('Power law conversion')\n","plt.show()\n","plt.figure(11)\n","imhist(L)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# © Copyright, Shogo MURAMATSU, All rights reserved."]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}
